# Grafana Tempo Configuration
# Project: {{PROJECT_NAME}}
# Author: {{AUTHOR}}

server:
  http_listen_port: 3200

distributor:
  receivers:
    jaeger:
      protocols:
        thrift_http:
          endpoint: 0.0.0.0:14268
        grpc:
          endpoint: 0.0.0.0:14250
        thrift_binary:
          endpoint: 0.0.0.0:6832
        thrift_compact:
          endpoint: 0.0.0.0:6831
    zipkin:
      endpoint: 0.0.0.0:9411
    otlp:
      protocols:
        http:
          endpoint: 0.0.0.0:4318
        grpc:
          endpoint: 0.0.0.0:4317

ingester:
  trace_idle_period: 10s
  max_block_bytes: 1_000_000
  max_block_duration: 5m

compactor:
  compaction:
    block_retention: 720h  # 30 days

storage:
  trace:
    backend: local
    local:
      path: /tmp/tempo/blocks
    wal:
      path: /tmp/tempo/wal
    pool:
      max_workers: 100
      queue_depth: 10000

# Query frontend
query_frontend:
  search:
    query_timeout: 30s
    max_duration: 0s

# Metrics generator
metrics_generator:
  registry:
    external_labels:
      source: tempo
      cluster: {{CLUSTER_NAME}}
  storage:
    path: /tmp/tempo/generator/wal
    remote_write:
      - url: http://prometheus:9090/api/v1/write
        send_exemplars: true

# Overrides
overrides:
  defaults:
    metrics_generator:
      processors: [service-graphs, span-metrics]
      generate_native_histograms: both

# For production, use S3 or GCS
# storage:
#   trace:
#     backend: s3
#     s3:
#       bucket: tempo-traces
#       endpoint: s3.amazonaws.com
#       region: {{AWS_REGION}}
